%Just putting something here as a placeholder...
%Not sure what to put here


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}


% The truth: I wanted to take paco's D18 course, but I couldn't afford it (both in time and money), so I wanted to do something graphics-y. 
%            It also somehow got into my head that raytracing black holes was something to do, I think maybe paco's students showed me?
% What I will tell people:

% Motivation... why we are doing this? and why is interesting...
Raytracing is a foundational technique in Computer Graphics, which can be used to render photorealistic scenes with the proper compute time and algorithms and images of Black Holes, such as M87 \cite{M87_EHT_i}, have captivated the minds of millions. Since we have well established equations for describing the trajectories of light rays around a black hole, it is natural to try to use a ray tracer to render a scene with this distortion applied.

% TODO: Other work section.
We should emphasize that there exist a vast variety of implementations
of raytracers
\cite{sharma2023mahakalapythonbasedmodularraytracing,James_2015,imbens2023graphicalprocessinggeodesicpropagation}
and even with direct astrophysical applications such as
the rendering of blakc hole sorroundings.
However, our approach seek to highlight some specific features:
i) its open-source implementation;
ii) the minimalistic and simplistic technicality, i.e. by tackling
mostly the actual mathematical problem using specialized libraries
to solve the governing ODE of the problen;
iii) the proximity to implement this in a farely efficient and high-performing
way by employing standards in shared-memory and distributed-memory paradigms;
and iv) the hardware agnostic approach, i.e. not depending on specialized hardware, accelerators or GPUs which one could argue would be much better suited for tackling this type of problems.


This paper is organized as follows:
in Sec.~\ref{sec:intro} we present the physical problem of tracing rays of light in the presence of a black hole;
in Sec.~\ref{sec:impl} we describe the methods implemented and used to tackle this problem;
in Sec.~\ref{sec:results} we discuss our results and compare to other related works;
and finally in Sec.~\ref{sec:disc} and ~\ref{sec:concl} we present our findings and comment
on possible future extensions to this work.


\subsection{The Schwartzschield metric}

The Schwartzschield metric can model black holes which, among other properties, are non-spinning and not charged, which implies that their deformation of the trajectories of light rays do not depend on the angle of approach. This paper \cite {federov2019notes} \CMT{need a better ref as these are just not refereed notes} Shows how we can derive the equation $ u'' - u = 3Mu^2 $, which relates the trajectory of a light ray to the mass of a black hole, from the Schwartzschield metric. For this equation, "u" represents 1/r, the euclidean distance of a point on the light ray to the black hole center. "u" is differentiated with respect to $ \phi $, the azimuthal angle between the point and the black hole origin. After providing initial conditions, we are able to use this equation to trace the entire trajectory of the ray with high fidelity. Notably, this equation is modeled in 2d-sphericial coordinates, meaning, if we want to use this equation to analyze light rays in 3D space, we need to find a way to find an equivalent ray that our equation models, and use the 2D ray to find the 3D ray's trajectory.

\subsection {Using this equation for ray tracing}

% TODO: Kinda boring...
After being able to compute the trajectory of individual rays, we wish to be able to use this insight to generate images. The natural technique is to use a ray tracer. Ray tracers render a simulated scene by casting light rays from a simulated camera, and computing what objects in the scene would be visable to that ray. If a particular camera would produce an image of 1920x1080 pixels, we could build the image that camera would record by casting a light ray through each pixel. Because ray tracing's unit of perception is how simulated light rays interact with a simulated scene, it is a natural choice for simulations which involve the bending or distortion of light.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation}
\label{sec:impl}


\subsection {Approximating the trajectory of a light ray as a piecewise function}
While the fundamental idea of taking a ray tracer and modifying it so that light rays are distorted is sound, the implementation of such an idea is fraught with difficulty. The first major challenge is that ray tracers need linear equations to be able to compute object intersection in a scene. This means we need to find a way to describe our light ray as a piecewise-defined set of linear equations. We found the best way to do this was to compute discrete points on the light ray, and compute intersection using the line segments defined by said points. 

\subsection {Using GSL for ODE approximation}
As for how to compute these segments, GSL's suite of ODE approximation tools found significant utility. GSL allows us to define our equations as C functions, and our particular ray by a set of initial condtions. From there, we can use GSL to compute a series of discrete points on the ray governed by a timestep of our choosing. For initial conditions, we need to describe,in 2D spherical coordinates, an initial point on the ray and a single successor point, which was computed using the linear direction, as we are casting rays far from the black hole's influence. As for the timestep (as it is commonly known in the GSL documentation), we allowed program users to control the "epsilon" of the simulation, with lower epsilon values resulting in more accurate trajectories. 

\subsection {Ensuring even spacing of computed points}
To compute the next point on a light ray `epsilon` distance away, we would compute, using the euclidean metric, the light ray's path with no distortion. In sphericial coordinates, this allows us to compute the azimuthal angle from the black hole's origin. We can feed this updated azimuthal angle into GSL, and it will return the distance of the ray from the origin of the black hole. In effect, GSL behaves as a function from azimuthal angle to distance, allowing us to compute the needed points in 2D space.  [TODO: needs diagram]

\subsection {Relating our 2-variable equation to 3D space.}
As noted earlier though, we cannot use the trajectories of rays in 2D space to render a 3D scene, meaning we need to find a way to find an invertible relationship between 3D rays and 2D rays. The solution here was to recognise that we could apply a combination of axis rotations and axis relabling to complete the correlation. If the "origin" of the light ray, and the origin of the black hole are both located on the z=0 axis, as is the case for our 3D scenes, we can rotate our ray around the z axis until the ray's direction vector has incline $ \pi / 2 $ with respect to the black hole origin, meaning the ray has no spherical incline. At this point, the y component of the ray's origin and direction will both be zero, meaning we have reduced our 3D ray to 2D. From here, we can easily convert to spherical coordinates for use with GSL. Since this process is invertible, we have now found a way to use GSL to trace the trajectory of light rays in 3D using an equation of two variables. [TODO: Fact check, crappy explanation, needs diagram].

\subsection {Image and scene handling}
% Large image challenges...
\subsection {Domain Decomposition}
\subsection {Use of OpenMP}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}
\label{sec:results}

\begin{itemize}
	\item Some rendered images
    	\item Scaling results after scaling image dimensions, potentially some other scaling analysis 
      which I previously did for my presentation.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:disc}

\subsection {Educational Value}


% TODO: Preferred title here?
This raytracer was originally developed for educational purposes in the context of Marcelo Ponce's course CSCD71. As a project, it combines physics simulations (both through the use of a raytracer, and through the simulation of gravitational distortion), ODE approximation with GSL, path stenciling, image/file parsing (esp. at large scale), parallel and distributed computing with MPI and OpenMP, domain decomposition, as well as providing a bountiful quantity of variant implementations, while being of low-enough difficulty to be completed in a few weeks (with great difficulty). The result of which is the ability to render pretty images. In particular, the project would provide potential students an excellent opportunity to learn the practical use of GSL/ODE approximation in a realistic context. The impact is felt in 3 areas:

1. Attempting to set up this particular system is theoretically easy and practically quite difficult. The initial conditions are not obvious. GSL asks for an initial radius, initial angle, and the derivative of the radius with respect to azimuthal angle. Unfortunately, it is not possible to find this derivative without an equation that models the trajectory of light rays, which is the equation we were trying to approximate in the first place! Solving this chicken-and-egg problem is a great educational experience, and forces one to consider more deeply the significance of the parameters given to GSL. 
% (TODO: mention that debugging is hell?)

2. Using GSL for course analysis is a nonstandard application. One key detail of the project is that we need to restrict the number of points GSL returns, while keeping the distance between points relatively even. (TODO: future work: dynamic spacing based off of distortion). The way this challenge was solved was by approximating the angle between the black hole on a line of potential future points, as described earlier, and having the GSL driver stencil the equation until it reaches said line. Idk some closer sentence.

3. The problem of relating the 2D ray-trajectory equation to a 3D scene has no readily available solutions. As such, it challenges potential students to think deeply about the problem, and to come up with original solutions.

Beyond the challenges associated with GSL, this project's requirement of parallel image processing provides an opportunity to learn how to process, parse, and generate large images in parallel. In particular, handling the case where the total handled image size is larger than system memory can yield many variant implementations with considerable performance differences and technical complexity. 

Finally, this project provides an opportunity to practice domain decomposition techniques in a practical setting. %TODO: not sure what else to add here...

Related and Future work

\subsection {General Applicability}
% TODO: Forgetting what else is good to put here...
\subsection {Performance Tuning}
\subsection {A better ray tracer (Also accretion disks)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}
\label{sec:concl}

This paper demonstrated a technique for rendering simulations of gravitational lensing with the use of a ray tracer, as well as methods for parallel processing. %TODO: Not sure what else to put here.

% TODO: Credit Ray Tracing in One Weekend somewhere...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
